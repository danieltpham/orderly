# ğŸ§¾ Orderly â€“ PO Line Item ETL Pipeline

_âš ï¸ Disclaimer: This project uses **synthetic data only**. No real or proprietary data is used._

## ğŸ¯ Problem Context
In large orgs or systems ingesting manual purchase entries:
- Item names are unstructured and vary across orders
- Similar products are priced differently or misclassified
- Vendor names come in many alias forms
- Orders are missing key fields or include malformed text

**Orderly** solves this by:
- Normalising item names, sizes, and units
- Matching line items to canonical SKUs via fuzzy logic
- Cleaning vendor aliases and cost centres
- Flagging duplicates, outliers, and incomplete entries

## ğŸ› ï¸ Key Skills Demonstrated

- AI Prompt Engineering (structured generation of messy PO records)
- ETL Design with Pydantic, pandas, DuckDB
- SKU + Vendor Fuzzy Matching (fuzzywuzzy, token sort, regex)
- Data Quality Validation (Great Expectations)
- Analytics Layer with dbt
- Modular pipeline with match logs, issue flags, config-based logic

```
orderly/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ orderly.duckdb                # Embedded DB file (auto-generated)
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Raw AI-generated or scraped input files
â”‚   â”‚   â”œâ”€â”€ line_items.jsonl
â”‚   â”‚   â”œâ”€â”€ vendor_master.csv
â”‚   â”‚   â”œâ”€â”€ sku_catalog.csv
â”‚   â”‚   â””â”€â”€ cost_centres.csv
â”‚   â”‚
â”‚   â””â”€â”€ prompts/
â”‚       â””â”€â”€ product_prompt.txt    # AI prompt used to generate fake line items
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                 # Paths, DuckDB schema names, constants
â”‚   â”œâ”€â”€ bronze_layer.py          # Reads raw files â†’ bronze DuckDB tables
â”‚   â”œâ”€â”€ clean_and_match.py       # Cleans + fuzzy matches â†’ silver tables
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ matching_utils.py     # Fuzzy logic, token helpers, etc.
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ dbt_project.yml
â”‚   â”œâ”€â”€ profiles.yml             # DuckDB dbt profile
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”‚   â”œâ”€â”€ line_items_clean.sql
â”‚   â”‚   â”‚   â”œâ”€â”€ vendor_dim.sql
â”‚   â”‚   â”‚   â””â”€â”€ sku_dim.sql
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ gold/
â”‚   â”‚       â”œâ”€â”€ fact_orders.sql
â”‚   â”‚       â”œâ”€â”€ spend_cube.sql
â”‚   â”‚       â””â”€â”€ anomaly_log.sql
â”‚   â”‚
â”‚   â””â”€â”€ seeds/
â”‚       â””â”€â”€ unit_standardisation.csv  # Optional helper maps for dbt
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ explore_sample_data.ipynb     # For quick inspection / demo
â”‚
â””â”€â”€ tests/
    â””â”€â”€ great_expectations/          # Optional data quality checks
```

## Layer Summary

| Layer      | Tools Used              | Location                                  |
| ---------- | ----------------------- | ----------------------------------------- |
| **Raw**    | Files (JSONL, CSV)      | `data/raw/`                               |
| **Bronze** | Python â†’ DuckDB         | `src/bronze_layer.py` â†’ `bronze.*` tables |
| **Silver** | Pandas + Fuzzy Matching | `src/clean_and_match.py` â†’ `silver.*`     |
| **Gold**   | dbt + DuckDB            | `dbt/models/gold/`                        |
