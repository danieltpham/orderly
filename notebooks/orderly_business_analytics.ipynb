{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4c1a11",
   "metadata": {},
   "source": [
    "# Orderly Data Platform - Business Analytics\n",
    "\n",
    "This notebook provides comprehensive business insights from the Orderly procurement data warehouse. It includes key analytics across procurement spend, data quality, price variance, regional performance, seasonal trends, vendor relationships, and executive KPIs.\n",
    "\n",
    "## Data Model Overview\n",
    "\n",
    "Our gold layer consists of:\n",
    "- **Dimension Tables**: `dim_date`, `dim_cost_centre`, `dim_vendor`, `dim_product`\n",
    "- **Fact Tables**: `fct_order_line`, `fct_data_quality`, `fct_price_variance`\n",
    "\n",
    "\n",
    "## 1. üí∞ **Procurement Spend Analysis**\n",
    "\n",
    "### Question: What are our top spending categories by cost centre and vendor over the last quarter?\n",
    "\n",
    "## 2. üìä **Data Quality Monitoring**\n",
    "\n",
    "### Question: What are the most common data quality issues and which cost centres have the highest exception rates?\n",
    "\n",
    "\n",
    "## 3. üîç **Price Variance & Anomaly Detection**\n",
    "\n",
    "### Question: Which products show the highest price volatility and potential savings opportunities?\n",
    "\n",
    "\n",
    "## 4. üåç **Multi-Region Cost Centre Performance**\n",
    "\n",
    "### Question: How do procurement patterns differ between AU and US cost centres?\n",
    "\n",
    "\n",
    "## 5. ‚è∞ **Seasonal Procurement Trends**\n",
    "\n",
    "### Question: What are the seasonal spending patterns and how do they vary by product category?\n",
    "\n",
    "## 6. üéØ **Vendor Performance & Relationship Analysis**\n",
    "\n",
    "### Question: Which vendors provide the best value and should we consolidate our vendor relationships?\n",
    "\n",
    "\n",
    "## 7. üìà **Executive Summary Dashboard Query**\n",
    "\n",
    "### Question: What are the key KPIs for executive reporting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2665315d",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "Import required libraries and configure plotting settings for data visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47b8459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported and plotting configured successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import duckdb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configure plotting settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings for pandas\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"‚úÖ Libraries imported and plotting configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0f6c77",
   "metadata": {},
   "source": [
    "## 2. Database Connection and Schema Validation\n",
    "\n",
    "Connect to the DuckDB warehouse database and validate that all required gold layer tables and columns exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e305859",
   "metadata": {},
   "outputs": [
    {
     "ename": "IOException",
     "evalue": "IO Error: Cannot open file \"d:\\nifinity\\personal website 2025\\orderly\\notebooks\\..\\warehouse\\orderly.duckdb\": The process cannot access the file because it is being used by another process.\r\n\nFile is already open in \nD:\\Programs\\DataGrip 2024.3.4\\jbr\\bin\\java.exe (PID 3116)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIOException\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m DB_PATH = \u001b[33m\"\u001b[39m\u001b[33m../warehouse/orderly.duckdb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Connect to DuckDB\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m conn = \u001b[43mduckdb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDB_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Connected to DuckDB: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDB_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Connection established at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIOException\u001b[39m: IO Error: Cannot open file \"d:\\nifinity\\personal website 2025\\orderly\\notebooks\\..\\warehouse\\orderly.duckdb\": The process cannot access the file because it is being used by another process.\r\n\nFile is already open in \nD:\\Programs\\DataGrip 2024.3.4\\jbr\\bin\\java.exe (PID 3116)"
     ]
    }
   ],
   "source": [
    "# Database connection\n",
    "DB_PATH = \"../warehouse/orderly.duckdb\"\n",
    "\n",
    "# Connect to DuckDB\n",
    "conn = duckdb.connect(DB_PATH, read_only=True)\n",
    "\n",
    "print(f\"‚úÖ Connected to DuckDB: {DB_PATH}\")\n",
    "print(f\"üìä Connection established at: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e2f5b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Schema Validation Results:\n",
      "                      table      status  row_count\n",
      "          dev_gold.dim_date ‚úÖ Available         92\n",
      "   dev_gold.dim_cost_centre ‚úÖ Available         12\n",
      "        dev_gold.dim_vendor ‚úÖ Available          6\n",
      "       dev_gold.dim_product ‚úÖ Available         40\n",
      "    dev_gold.fct_order_line ‚úÖ Available        267\n",
      "  dev_gold.fct_data_quality ‚úÖ Available        157\n",
      "dev_gold.fct_price_variance ‚úÖ Available          1\n",
      "\n",
      "üìä Total available tables: 7/7\n",
      "üìà Total rows across all tables: 575\n"
     ]
    }
   ],
   "source": [
    "# Validate schema and tables exist\n",
    "def validate_schema():\n",
    "    \"\"\"Validate that all required tables exist in the gold schema\"\"\"\n",
    "    \n",
    "    required_tables = [\n",
    "        'dev_gold.dim_date',\n",
    "        'dev_gold.dim_cost_centre', \n",
    "        'dev_gold.dim_vendor',\n",
    "        'dev_gold.dim_product',\n",
    "        'dev_gold.fct_order_line',\n",
    "        'dev_gold.fct_data_quality',\n",
    "        'dev_gold.fct_price_variance'\n",
    "    ]\n",
    "    \n",
    "    validation_results = []\n",
    "    \n",
    "    for table in required_tables:\n",
    "        try:\n",
    "            result = conn.execute(f\"SELECT COUNT(*) as row_count FROM {table}\").fetchone()\n",
    "            row_count = result[0] if result else 0\n",
    "            validation_results.append({\n",
    "                'table': table,\n",
    "                'status': '‚úÖ Available',\n",
    "                'row_count': row_count\n",
    "            })\n",
    "        except Exception as e:\n",
    "            validation_results.append({\n",
    "                'table': table,\n",
    "                'status': f'‚ùå Error: {str(e)[:50]}...',\n",
    "                'row_count': 0\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(validation_results)\n",
    "\n",
    "# Run validation\n",
    "schema_validation = validate_schema()\n",
    "print(\"üìã Schema Validation Results:\")\n",
    "print(schema_validation.to_string(index=False))\n",
    "\n",
    "# Check if all tables are available\n",
    "available_tables = schema_validation[schema_validation['status'].str.contains('‚úÖ')]\n",
    "print(f\"\\nüìä Total available tables: {len(available_tables)}/7\")\n",
    "print(f\"üìà Total rows across all tables: {schema_validation['row_count'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364f166e",
   "metadata": {},
   "source": [
    "## 3. üí∞ Procurement Spend Analysis\n",
    "\n",
    "Execute queries to analyze top spending categories by cost centre and vendor over the last quarter, with visualizations of spend patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a827a969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Executing Procurement Spend Analysis...\n"
     ]
    },
    {
     "ename": "BinderException",
     "evalue": "Binder Error: Table \"dd\" does not have a column named \"year_actual\"\n\nCandidate bindings: : \"date_actual\"\n\nLINE 10:         dd.year_actual,\n                 ^",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBinderException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m     procurement_query = f.read()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîç Executing Procurement Spend Analysis...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m procurement_df = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocurement_query\u001b[49m\u001b[43m)\u001b[49m.df()\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müìä Results: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(procurement_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m records found\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müîù Top 10 Spending Categories:\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mBinderException\u001b[39m: Binder Error: Table \"dd\" does not have a column named \"year_actual\"\n\nCandidate bindings: : \"date_actual\"\n\nLINE 10:         dd.year_actual,\n                 ^"
     ]
    }
   ],
   "source": [
    "# Load and execute procurement spend analysis query\n",
    "with open('../notebooks/sql/1_procurement_spend_analysis.sql', 'r') as f:\n",
    "    procurement_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Procurement Spend Analysis...\")\n",
    "procurement_df = conn.execute(procurement_query).df()\n",
    "\n",
    "print(f\"üìä Results: {len(procurement_df)} records found\")\n",
    "print(\"\\nüîù Top 10 Spending Categories:\")\n",
    "display(procurement_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895ef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Top spending by cost centre\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Top 10 Cost Centres by Spend\n",
    "top_cost_centres = procurement_df.groupby('cost_centre_name')['total_spend_aud'].sum().sort_values(ascending=False).head(10)\n",
    "top_cost_centres.plot(kind='bar', ax=ax1, color='steelblue')\n",
    "ax1.set_title('Top 10 Cost Centres by Total Spend (AUD)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Cost Centre')\n",
    "ax1.set_ylabel('Total Spend (AUD)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Top 10 Vendors by Spend\n",
    "top_vendors = procurement_df.groupby('vendor_name')['total_spend_aud'].sum().sort_values(ascending=False).head(10)\n",
    "top_vendors.plot(kind='bar', ax=ax2, color='coral')\n",
    "ax2.set_title('Top 10 Vendors by Total Spend (AUD)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Vendor')\n",
    "ax2.set_ylabel('Total Spend (AUD)')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Spend by Product Category\n",
    "category_spend = procurement_df.groupby('product_category')['total_spend_aud'].sum().sort_values(ascending=False)\n",
    "category_spend.plot(kind='pie', ax=ax3, autopct='%1.1f%%')\n",
    "ax3.set_title('Spend Distribution by Product Category', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('')\n",
    "\n",
    "# 4. Quantity vs Spend Correlation\n",
    "ax4.scatter(procurement_df['total_quantity'], procurement_df['total_spend_aud'], alpha=0.6, color='green')\n",
    "ax4.set_title('Quantity vs Total Spend Correlation', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Total Quantity')\n",
    "ax4.set_ylabel('Total Spend (AUD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìà Procurement Spend Summary:\")\n",
    "print(f\"üí∞ Total Spend (AUD): ${procurement_df['total_spend_aud'].sum():,.2f}\")\n",
    "print(f\"üì¶ Total Quantity: {procurement_df['total_quantity'].sum():,.0f}\")\n",
    "print(f\"üìã Total Order Lines: {procurement_df['order_line_count'].sum():,.0f}\")\n",
    "print(f\"üíµ Average Cost per Unit: ${procurement_df['avg_cost_per_unit'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb5cc2",
   "metadata": {},
   "source": [
    "## 4. üìä Data Quality Monitoring\n",
    "\n",
    "Run data quality exception analysis to identify common issues and cost centres with highest exception rates, including trend charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71463d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute data quality monitoring query\n",
    "with open('../notebooks/sql/2_data_quality_monitoring.sql', 'r') as f:\n",
    "    quality_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Data Quality Monitoring Analysis...\")\n",
    "quality_df = conn.execute(quality_query).df()\n",
    "\n",
    "print(f\"üìä Results: {len(quality_df)} exception records found\")\n",
    "print(\"\\n‚ö†Ô∏è Top 10 Exception Areas:\")\n",
    "display(quality_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47292fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Data Quality Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Exception Count by Cost Centre\n",
    "cc_exceptions = quality_df.groupby('cost_centre_name')['exception_count'].sum().sort_values(ascending=False).head(10)\n",
    "cc_exceptions.plot(kind='bar', ax=ax1, color='red', alpha=0.7)\n",
    "ax1.set_title('Top 10 Cost Centres by Exception Count', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Cost Centre')\n",
    "ax1.set_ylabel('Exception Count')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Exception Types Distribution\n",
    "exception_types = quality_df.groupby('exception_type')['exception_count'].sum().sort_values(ascending=False)\n",
    "exception_types.plot(kind='pie', ax=ax2, autopct='%1.1f%%')\n",
    "ax2.set_title('Exception Types Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "# 3. Exception Rate Distribution\n",
    "quality_df['exception_rate_percent'].hist(bins=20, ax=ax3, color='orange', alpha=0.7)\n",
    "ax3.set_title('Distribution of Exception Rates', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Exception Rate (%)')\n",
    "ax3.set_ylabel('Frequency')\n",
    "\n",
    "# 4. Fuzz Score vs Exception Rate\n",
    "ax4.scatter(quality_df['avg_fuzz_score'], quality_df['exception_rate_percent'], alpha=0.6, color='purple')\n",
    "ax4.set_title('Fuzz Score vs Exception Rate', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Average Fuzz Score')\n",
    "ax4.set_ylabel('Exception Rate (%)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìä Data Quality Summary:\")\n",
    "print(f\"‚ö†Ô∏è Total Exceptions: {quality_df['exception_count'].sum():,.0f}\")\n",
    "print(f\"üìä Average Exception Rate: {quality_df['exception_rate_percent'].mean():.2f}%\")\n",
    "print(f\"üéØ Average Fuzz Score: {quality_df['avg_fuzz_score'].mean():.2f}\")\n",
    "print(f\"üîç Missing in Seed Issues: {quality_df['missing_in_seed_count'].sum():,.0f}\")\n",
    "print(f\"üìù Name Mismatch Issues: {quality_df['name_mismatch_count'].sum():,.0f}\")\n",
    "print(f\"üè¢ Vendor Mismatch Issues: {quality_df['vendor_mismatch_count'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b578b4",
   "metadata": {},
   "source": [
    "## 5. üîç Price Variance and Anomaly Detection\n",
    "\n",
    "Analyze price volatility and identify potential savings opportunities through price variance analysis with statistical visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e94dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute price variance analysis query\n",
    "with open('../notebooks/sql/3_price_variance_analysis.sql', 'r') as f:\n",
    "    price_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Price Variance Analysis...\")\n",
    "price_df = conn.execute(price_query).df()\n",
    "\n",
    "print(f\"üìä Results: {len(price_df)} products with significant price variance\")\n",
    "print(\"\\nüí∞ Top 10 Savings Opportunities:\")\n",
    "display(price_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Price Variance Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Top 15 Products by Potential Savings\n",
    "top_savings = price_df.head(15)\n",
    "bars = ax1.bar(range(len(top_savings)), top_savings['potential_savings_aud'], color='green', alpha=0.7)\n",
    "ax1.set_title('Top 15 Products by Potential Savings (AUD)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Product Rank')\n",
    "ax1.set_ylabel('Potential Savings (AUD)')\n",
    "ax1.set_xticks(range(len(top_savings)))\n",
    "ax1.set_xticklabels([f\"P{i+1}\" for i in range(len(top_savings))])\n",
    "\n",
    "# 2. Price Volatility Distribution\n",
    "price_df['price_volatility_percent'].hist(bins=20, ax=ax2, color='red', alpha=0.7)\n",
    "ax2.set_title('Price Volatility Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Price Volatility (%)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "# 3. Savings by Product Category\n",
    "category_savings = price_df.groupby('product_category')['potential_savings_aud'].sum().sort_values(ascending=False)\n",
    "category_savings.plot(kind='pie', ax=ax3, autopct='%1.1f%%')\n",
    "ax3.set_title('Potential Savings by Product Category', fontsize=12, fontweight='bold')\n",
    "ax3.set_ylabel('')\n",
    "\n",
    "# 4. Volatility vs Savings Scatter\n",
    "ax4.scatter(price_df['price_volatility_percent'], price_df['potential_savings_aud'], alpha=0.6, color='blue')\n",
    "ax4.set_title('Price Volatility vs Potential Savings', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Price Volatility (%)')\n",
    "ax4.set_ylabel('Potential Savings (AUD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìà Price Variance Summary:\")\n",
    "print(f\"üí∞ Total Potential Savings: ${price_df['potential_savings_aud'].sum():,.2f}\")\n",
    "print(f\"üìä Average Price Volatility: {price_df['price_volatility_percent'].mean():.2f}%\")\n",
    "print(f\"üì¶ Products Analyzed: {len(price_df):,.0f}\")\n",
    "print(f\"üéØ Highest Single Saving Opportunity: ${price_df['potential_savings_aud'].max():,.2f}\")\n",
    "print(f\"üìã Average Orders per Product: {price_df['order_count'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19697e16",
   "metadata": {},
   "source": [
    "## 6. üåç Multi-Region Cost Centre Performance\n",
    "\n",
    "Compare procurement patterns between AU and US cost centres with regional performance metrics and comparative charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute multi-region performance query\n",
    "with open('../notebooks/sql/4_multi_region_performance.sql', 'r') as f:\n",
    "    region_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Multi-Region Performance Analysis...\")\n",
    "region_df = conn.execute(region_query).df()\n",
    "\n",
    "print(f\"üìä Results: {len(region_df)} regional performance records\")\n",
    "print(\"\\nüåç Regional Performance Overview:\")\n",
    "display(region_df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d1741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Multi-Region Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Spend by Country and Region\n",
    "country_spend = region_df.groupby('country_code')['region_total_spend_aud'].sum()\n",
    "country_spend.plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\n",
    "ax1.set_title('Total Spend by Country (AUD)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Country Code')\n",
    "ax1.set_ylabel('Total Spend (AUD)')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Average Order Value by Country\n",
    "country_order_value = region_df.groupby('country_code')['avg_order_value'].mean()\n",
    "country_order_value.plot(kind='bar', ax=ax2, color=['orange', 'green'])\n",
    "ax2.set_title('Average Order Value by Country (AUD)', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Country Code')\n",
    "ax2.set_ylabel('Average Order Value (AUD)')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 3. Vendor Category Distribution by Country\n",
    "vendor_category_pivot = region_df.pivot_table(\n",
    "    values='region_total_spend_aud', \n",
    "    index='country_code', \n",
    "    columns='vendor_category', \n",
    "    aggfunc='sum', \n",
    "    fill_value=0\n",
    ")\n",
    "vendor_category_pivot.plot(kind='bar', stacked=True, ax=ax3, alpha=0.8)\n",
    "ax3.set_title('Spend by Vendor Category and Country', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Country Code')\n",
    "ax3.set_ylabel('Total Spend (AUD)')\n",
    "ax3.tick_params(axis='x', rotation=0)\n",
    "ax3.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# 4. Efficiency Metrics Comparison\n",
    "efficiency_metrics = region_df.groupby('country_code')[['avg_lines_per_order', 'avg_vendors_per_cc', 'avg_products_per_cc']].mean()\n",
    "efficiency_metrics.plot(kind='bar', ax=ax4, alpha=0.8)\n",
    "ax4.set_title('Operational Efficiency Metrics by Country', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Country Code')\n",
    "ax4.set_ylabel('Average Count')\n",
    "ax4.tick_params(axis='x', rotation=0)\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics by country\n",
    "print(\"\\nüåç Regional Performance Summary:\")\n",
    "country_summary = region_df.groupby('country_code').agg({\n",
    "    'region_total_spend_aud': 'sum',\n",
    "    'total_orders': 'sum',\n",
    "    'total_line_items': 'sum',\n",
    "    'avg_order_value': 'mean',\n",
    "    'avg_lines_per_order': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "display(country_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eba762",
   "metadata": {},
   "source": [
    "## 7. ‚è∞ Seasonal Procurement Trends\n",
    "\n",
    "Examine seasonal spending patterns by product category using time series analysis and seasonal decomposition plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c348820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute seasonal trends analysis query\n",
    "with open('../notebooks/sql/5_seasonal_trends.sql', 'r') as f:\n",
    "    seasonal_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Seasonal Trends Analysis...\")\n",
    "seasonal_df = conn.execute(seasonal_query).df()\n",
    "\n",
    "print(f\"üìä Results: {len(seasonal_df)} monthly trend records\")\n",
    "print(\"\\nüìÖ Sample Seasonal Trends:\")\n",
    "display(seasonal_df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122904b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Seasonal Trends Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Monthly Spend Trends by Quarter\n",
    "quarterly_spend = seasonal_df.groupby(['quarter_name', 'month_name'])['monthly_spend_aud'].sum().reset_index()\n",
    "quarter_pivot = quarterly_spend.pivot(index='month_name', columns='quarter_name', values='monthly_spend_aud')\n",
    "quarter_pivot.plot(kind='bar', ax=ax1, alpha=0.8)\n",
    "ax1.set_title('Monthly Spend by Quarter (AUD)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Monthly Spend (AUD)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Seasonality Z-Score Distribution\n",
    "seasonal_df['spend_seasonality_zscore'].hist(bins=20, ax=ax2, color='purple', alpha=0.7)\n",
    "ax2.set_title('Seasonality Z-Score Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Seasonality Z-Score')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.axvline(0, color='red', linestyle='--', alpha=0.7, label='Average')\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Top Product Categories by Seasonal Variance\n",
    "category_variance = seasonal_df.groupby('product_category')['spend_variance_from_avg_percent'].std().sort_values(ascending=False).head(10)\n",
    "category_variance.plot(kind='bar', ax=ax3, color='orange', alpha=0.7)\n",
    "ax3.set_title('Top 10 Categories by Seasonal Variance', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Product Category')\n",
    "ax3.set_ylabel('Variance Standard Deviation (%)')\n",
    "ax3.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 4. Monthly Orders vs Spend Correlation\n",
    "ax4.scatter(seasonal_df['monthly_orders'], seasonal_df['monthly_spend_aud'], alpha=0.6, color='green')\n",
    "ax4.set_title('Monthly Orders vs Monthly Spend', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Monthly Orders')\n",
    "ax4.set_ylabel('Monthly Spend (AUD)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nüìÖ Seasonal Trends Summary:\")\n",
    "print(f\"üìä Average Monthly Spend: ${seasonal_df['monthly_spend_aud'].mean():,.2f}\")\n",
    "print(f\"üìà Peak Monthly Spend: ${seasonal_df['monthly_spend_aud'].max():,.2f}\")\n",
    "print(f\"üìâ Lowest Monthly Spend: ${seasonal_df['monthly_spend_aud'].min():,.2f}\")\n",
    "print(f\"üéØ Seasonality Score Range: {seasonal_df['spend_seasonality_zscore'].min():.2f} to {seasonal_df['spend_seasonality_zscore'].max():.2f}\")\n",
    "print(f\"üì¶ Product Categories Analyzed: {seasonal_df['product_category'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb093cb",
   "metadata": {},
   "source": [
    "## 8. üéØ Vendor Performance and Relationship Analysis\n",
    "\n",
    "Evaluate vendor performance metrics and identify consolidation opportunities through comprehensive vendor scorecards and rankings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e1cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute vendor performance analysis query\n",
    "with open('../notebooks/sql/6_vendor_performance.sql', 'r') as f:\n",
    "    vendor_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Vendor Performance Analysis...\")\n",
    "vendor_df = conn.execute(vendor_query).df()\n",
    "\n",
    "print(f\"üìä Results: {len(vendor_df)} vendor performance records\")\n",
    "print(\"\\nüèÜ Top 10 Vendors by Spend:\")\n",
    "display(vendor_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e02ffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Vendor Performance Analysis\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Top 15 Vendors by Spend\n",
    "top_vendors_spend = vendor_df.head(15)\n",
    "bars = ax1.bar(range(len(top_vendors_spend)), top_vendors_spend['total_spend_aud'], color='gold', alpha=0.8)\n",
    "ax1.set_title('Top 15 Vendors by Total Spend (AUD)', fontsize=12, fontweight='bold')\n",
    "ax1.set_xlabel('Vendor Rank')\n",
    "ax1.set_ylabel('Total Spend (AUD)')\n",
    "ax1.set_xticks(range(len(top_vendors_spend)))\n",
    "ax1.set_xticklabels([f\"V{i+1}\" for i in range(len(top_vendors_spend))])\n",
    "\n",
    "# 2. Vendor Classification Distribution\n",
    "classification_counts = vendor_df['vendor_classification'].value_counts()\n",
    "classification_counts.plot(kind='pie', ax=ax2, autopct='%1.1f%%')\n",
    "ax2.set_title('Vendor Classification Distribution', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "# 3. Spend Concentration Analysis\n",
    "vendor_df['spend_concentration_percent'].hist(bins=20, ax=ax3, color='red', alpha=0.7)\n",
    "ax3.set_title('Vendor Spend Concentration Distribution', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Spend Concentration (%)')\n",
    "ax3.set_ylabel('Number of Vendors')\n",
    "ax3.axvline(vendor_df['spend_concentration_percent'].mean(), color='red', linestyle='--', label='Average')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Quality Score vs Spend Relationship\n",
    "# Create a quality score based on data quality issues (inverse)\n",
    "vendor_df['quality_score'] = 100 - vendor_df['data_quality_issues']\n",
    "ax4.scatter(vendor_df['quality_score'], vendor_df['total_spend_aud'], \n",
    "           alpha=0.6, c=vendor_df['spend_rank'], cmap='viridis')\n",
    "ax4.set_title('Vendor Quality vs Spend (Color = Spend Rank)', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Quality Score (100 - Data Quality Issues)')\n",
    "ax4.set_ylabel('Total Spend (AUD)')\n",
    "cbar = plt.colorbar(ax4.collections[0], ax=ax4)\n",
    "cbar.set_label('Spend Rank')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Vendor Classification Summary\n",
    "print(\"\\nüéØ Vendor Performance Summary:\")\n",
    "classification_summary = vendor_df.groupby('vendor_classification').agg({\n",
    "    'vendor_name': 'count',\n",
    "    'total_spend_aud': ['sum', 'mean'],\n",
    "    'spend_concentration_percent': 'sum',\n",
    "    'data_quality_issues': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "# Flatten column names\n",
    "classification_summary.columns = ['vendor_count', 'total_spend_sum', 'avg_spend_per_vendor', 'total_concentration', 'avg_quality_issues']\n",
    "display(classification_summary)\n",
    "\n",
    "print(f\"\\nüìà Top Vendor Insights:\")\n",
    "print(f\"ü•á Highest Spending Vendor: {vendor_df.iloc[0]['vendor_name']} (${vendor_df.iloc[0]['total_spend_aud']:,.2f})\")\n",
    "print(f\"‚≠ê Strategic Partners: {len(vendor_df[vendor_df['vendor_classification'] == 'Strategic Partner'])}\")\n",
    "print(f\"üîÑ Consolidation Candidates: {len(vendor_df[vendor_df['vendor_classification'] == 'Consolidation Candidate'])}\")\n",
    "print(f\"üìä Total Vendor Concentration: {vendor_df['spend_concentration_percent'].sum():.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4460578d",
   "metadata": {},
   "source": [
    "## 9. üìà Executive Summary Dashboard\n",
    "\n",
    "Generate key KPIs for executive reporting including month-over-month growth metrics and quality scores with summary visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aceff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and execute executive dashboard query\n",
    "with open('../notebooks/sql/7_executive_dashboard.sql', 'r') as f:\n",
    "    executive_query = f.read()\n",
    "\n",
    "print(\"üîç Executing Executive Dashboard Analysis...\")\n",
    "executive_df = conn.execute(executive_query).df()\n",
    "\n",
    "print(f\"üìä Executive KPI Results:\")\n",
    "display(executive_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executive Dashboard Visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "\n",
    "# Create a dashboard layout\n",
    "gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# KPI Cards (Top Row)\n",
    "periods = ['Current Month', 'Previous Month', 'Year to Date']\n",
    "colors = ['#2E8B57', '#4682B4', '#DAA520']\n",
    "\n",
    "for i, period in enumerate(periods):\n",
    "    if period in executive_df['period_name'].values:\n",
    "        data = executive_df[executive_df['period_name'] == period].iloc[0]\n",
    "        \n",
    "        ax = fig.add_subplot(gs[0, i])\n",
    "        ax.text(0.5, 0.7, f\"{period}\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "        ax.text(0.5, 0.5, f\"${data['total_spend_aud']:,.0f}\", ha='center', va='center', fontsize=16, color=colors[i])\n",
    "        ax.text(0.5, 0.3, f\"{data['total_orders']:,.0f} Orders\", ha='center', va='center', fontsize=10)\n",
    "        ax.text(0.5, 0.1, f\"{data['active_vendors']:,.0f} Vendors\", ha='center', va='center', fontsize=10)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # Add border\n",
    "        rect = plt.Rectangle((0.05, 0.05), 0.9, 0.9, linewidth=2, edgecolor=colors[i], facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "# Growth Indicator\n",
    "if not executive_df[executive_df['period_name'] == 'Current Month']['mom_spend_growth_percent'].isna().all():\n",
    "    growth = executive_df[executive_df['period_name'] == 'Current Month']['mom_spend_growth_percent'].iloc[0]\n",
    "    ax_growth = fig.add_subplot(gs[0, 3])\n",
    "    color = 'green' if growth >= 0 else 'red'\n",
    "    ax_growth.text(0.5, 0.7, \"MoM Growth\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "    ax_growth.text(0.5, 0.3, f\"{growth:.1f}%\", ha='center', va='center', fontsize=20, color=color, fontweight='bold')\n",
    "    ax_growth.set_xlim(0, 1)\n",
    "    ax_growth.set_ylim(0, 1)\n",
    "    ax_growth.axis('off')\n",
    "    \n",
    "    # Add border\n",
    "    rect = plt.Rectangle((0.05, 0.05), 0.9, 0.9, linewidth=2, edgecolor=color, facecolor='none')\n",
    "    ax_growth.add_patch(rect)\n",
    "\n",
    "# Spend Trend Chart (Middle Left)\n",
    "ax1 = fig.add_subplot(gs[1, :2])\n",
    "spend_data = executive_df[executive_df['period_name'].isin(['Previous Month', 'Current Month'])]\n",
    "ax1.bar(spend_data['period_name'], spend_data['total_spend_aud'], color=['lightblue', 'steelblue'], alpha=0.8)\n",
    "ax1.set_title('Monthly Spend Comparison (AUD)', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Total Spend (AUD)')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Key Metrics Comparison (Middle Right)\n",
    "ax2 = fig.add_subplot(gs[1, 2:])\n",
    "metrics = ['total_orders', 'active_vendors', 'unique_products']\n",
    "metric_labels = ['Orders', 'Vendors', 'Products']\n",
    "current_data = executive_df[executive_df['period_name'] == 'Current Month'].iloc[0]\n",
    "previous_data = executive_df[executive_df['period_name'] == 'Previous Month'].iloc[0]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax2.bar(x - width/2, [previous_data[m] for m in metrics], width, label='Previous Month', alpha=0.8, color='lightcoral')\n",
    "bars2 = ax2.bar(x + width/2, [current_data[m] for m in metrics], width, label='Current Month', alpha=0.8, color='lightgreen')\n",
    "\n",
    "ax2.set_title('Key Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels(metric_labels)\n",
    "ax2.legend()\n",
    "\n",
    "# Data Quality Summary (Bottom)\n",
    "ax3 = fig.add_subplot(gs[2, :])\n",
    "quality_data = executive_df[executive_df['period_name'] == 'Current Month'].iloc[0]\n",
    "quality_score = quality_data['avg_data_quality_score']\n",
    "total_exceptions = quality_data['total_exceptions']\n",
    "\n",
    "# Create a gauge-like visualization for data quality\n",
    "theta = np.linspace(0, np.pi, 100)\n",
    "quality_normalized = quality_score / 100  # Assuming quality score is 0-100\n",
    "colors_grad = plt.cm.RdYlGn(np.linspace(0, 1, 100))\n",
    "\n",
    "for i, (t, c) in enumerate(zip(theta, colors_grad)):\n",
    "    if i/100 <= quality_normalized:\n",
    "        ax3.plot([t, t], [0.8, 1], color=c, linewidth=3)\n",
    "\n",
    "ax3.text(np.pi/2, 0.5, f\"Data Quality Score\\n{quality_score:.1f}/100\", ha='center', va='center', fontsize=14, fontweight='bold')\n",
    "ax3.text(np.pi/2, 0.2, f\"Exceptions: {total_exceptions:.0f}\", ha='center', va='center', fontsize=12)\n",
    "ax3.set_xlim(0, np.pi)\n",
    "ax3.set_ylim(0, 1.2)\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Data Quality Dashboard', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.suptitle('üìà Orderly Procurement - Executive Dashboard', fontsize=18, fontweight='bold', y=0.95)\n",
    "plt.show()\n",
    "\n",
    "# Executive Summary Text\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üìã EXECUTIVE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "current = executive_df[executive_df['period_name'] == 'Current Month'].iloc[0]\n",
    "previous = executive_df[executive_df['period_name'] == 'Previous Month'].iloc[0]\n",
    "ytd = executive_df[executive_df['period_name'] == 'Year to Date'].iloc[0]\n",
    "\n",
    "print(f\"üí∞ CURRENT MONTH PERFORMANCE:\")\n",
    "print(f\"   ‚Ä¢ Total Spend: ${current['total_spend_aud']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ Total Orders: {current['total_orders']:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Active Vendors: {current['active_vendors']:,.0f}\")\n",
    "print(f\"   ‚Ä¢ Average Line Value: ${current['avg_line_value']:,.2f}\")\n",
    "\n",
    "if not pd.isna(current['mom_spend_growth_percent']):\n",
    "    growth_direction = \"üìà INCREASED\" if current['mom_spend_growth_percent'] >= 0 else \"üìâ DECREASED\"\n",
    "    print(f\"\\nüìä MONTH-OVER-MONTH: Spend {growth_direction} by {abs(current['mom_spend_growth_percent']):.1f}%\")\n",
    "\n",
    "print(f\"\\nüóìÔ∏è YEAR-TO-DATE TOTALS:\")\n",
    "print(f\"   ‚Ä¢ YTD Spend: ${ytd['total_spend_aud']:,.2f}\")\n",
    "print(f\"   ‚Ä¢ YTD Orders: {ytd['total_orders']:,.0f}\")\n",
    "print(f\"   ‚Ä¢ YTD Vendors: {ytd['active_vendors']:,.0f}\")\n",
    "\n",
    "print(f\"\\nüéØ DATA QUALITY METRICS:\")\n",
    "print(f\"   ‚Ä¢ Quality Score: {current['avg_data_quality_score']:.1f}/100\")\n",
    "print(f\"   ‚Ä¢ Total Exceptions: {current['total_exceptions']:,.0f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7855fc",
   "metadata": {},
   "source": [
    "## üîß Cleanup and Connection Management\n",
    "\n",
    "Close database connection and cleanup resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a061c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close database connection\n",
    "conn.close()\n",
    "print(\"‚úÖ Database connection closed successfully\")\n",
    "print(f\"üìä Analysis completed at: {datetime.now()}\")\n",
    "print(\"\\nüéâ Orderly Business Analytics Report Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamride",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
